{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Imagens usando Deep Neural Network: aplicação\n",
    "\n",
    "Quando você terminar esta tarefa você terá encerrado a útlima tarefa deste módulo. \n",
    "\n",
    "Você irá utilizar as funções que você implementou na tarefa anterior para construir uma rede neural profunda, e aplicar esta rede na classificação gato vs não-gato. Esperamos que exista uma melhora na precisão desta rede quando comparada com a implementação utilizando regressão logística.  \n",
    "\n",
    "**Após esta tarefa você será capaz de:**\n",
    "- Construir e aplicar redes neurais profundas em aprendizado supervisionado.  \n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Pacotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos primeiro importar todos os pacotes que serão utilizados durante esta tarefa.  \n",
    "- [numpy](www.numpy.org) é o pacote para computação científica do Python. \n",
    "- [matplotlib](http://matplotlib.org) é a biblioteca para plotar gráficos do Python.\n",
    "- [h5py](http://www.h5py.org) é um pacote comum para interagir com uma base de dados armazenada em um arquivo H5.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) e [scipy](https://www.scipy.org/) são usadas para testar o modelo com uma imagem qualquer.\n",
    "- dnn_app_utils possui as funções implementadas na tarefa anterior. \n",
    "- np.random.seed(1) é utilizada para criar chamadas consistentes. Não altere a semente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # ajusta valores default para plotagem de imagens\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Base de dados\n",
    "\n",
    "Vamos utilizar a mesma base de dados \"Gato vs não-Gato\" utilizada no exemplo implementado com regressão logística. Aquele modelo, você deve se lembrar, possui uma precisão de 70% para a classificação utilizando o conjunto de teste. Esperamos que este novo modelo tenha um desempenho melhor! \n",
    "\n",
    "**Problema**: dada uma base de dados (\"data.h5\") contendo:\n",
    "    - um conjunto de treinamento contendo m_train imagens classificadas como gato (1) ou não-gato (0)\n",
    "    - um conjunto de teste com m_test imagens classificadas como gato ou não-gato.\n",
    "    - cada imagem está no formato (num_px, num_px, 3) onde 3 é o número de canais (RGB).\n",
    "\n",
    "Vamos nos familiarizar com esta base de dados. Execute a célula abaixo para carregar a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo irá apresentar uma das imagens da base de dados. Sinta-se a vontade para alterar o valor do index e ver outras imagens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de imagem\n",
    "index = 17\n",
    "plt.imshow(train_x_orig[index])\n",
    "print (\"y = \" + str(train_y[0,index]) + \". É uma imagem de \" + classes[train_y[0,index]].decode(\"utf-8\") +  \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore sua base de dados \n",
    "m_train = train_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "m_test = test_x_orig.shape[0]\n",
    "\n",
    "print (\"Numero de exemplos de treinamento: \" + str(m_train))\n",
    "print (\"Numero de exemplos de teste: \" + str(m_test))\n",
    "print (\"Tamanho de cada imagem: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"Formato do train_x_orig: \" + str(train_x_orig.shape))\n",
    "print (\"Formato do train_y: \" + str(train_y.shape))\n",
    "print (\"Formato do test_x_orig: \" + str(test_x_orig.shape))\n",
    "print (\"Formato do test_y: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sempre, reformatamos e normalizamos as imagens antes de utilizá-las na rede neural. O código é dado na célula abaixo. \n",
    "\n",
    "<img src=\"images/imvectorkiank.png\" style=\"width:450px;height:300px;\">\n",
    "\n",
    "<caption><center> <u>Figura 1</u>: Conversão de imagem para vetor. <br> </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformate os exemplos de treinamento e de teste \n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # O \"-1\" faz com que as demais dimensões fiquem achatadas.\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Normaliza os dados para ter os valores das características entre 0 e 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"Formato do train_x: \" + str(train_x.shape))\n",
    "print (\"Formato do test_x: \" + str(test_x.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$12,288$ é igual a $64 \\times 64 \\times 3$ que é o tamanho de um vetor reformatado da imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Arquitetura do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que você já está familiarizado com a base de dados, está na hora de construir uma rede neural profunda para classificar imagens como gatos ou não-gatos. \n",
    "\n",
    "Iremos construir dois modelos diferentes:\n",
    "- Uma rede neural com duas camadas escondidas.\n",
    "- Uma rede neural com L camadas escondidas.\n",
    "\n",
    "Será possível então comparar o desempenho destes dois modelos tentando valores diferentes para $L$.  \n",
    "\n",
    "Vamos dar uma olhada nas duas arquiteturas.\n",
    "\n",
    "### 3.1 - Rede Neural de 2 camadas\n",
    "\n",
    "<img src=\"images/2layerNN_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "<caption><center> <u>Figura 2</u>: Rede Neural com 2 camadas escondidas. <br> O modelo pode ser resumido como:***INPUT -> LINEAR -> RELU -> LINEAR -> SIGMOID -> OUTPUT***. </center></caption>\n",
    "\n",
    "<u>Arquitetura detalhada da Figura 2</u>:\n",
    "- O tamanho da imagem de entrada é (64,64,3) que é transformada em um vetor de tamanho $(12288,1)$. \n",
    "- O vetor correspondente: $[x_0,x_1,...,x_{12287}]^T$ é multiplicado pelo peso da matriz $W^{[1]}$ de tamanho $(n^{[1]}, 12288)$.\n",
    "- Adiciona-se um termo de bias e determina-se o valor da ReLu para obter o seguinte vetor: $[a_0^{[1]}, a_1^{[1]},..., a_{n^{[1]}-1}^{[1]}]^T$.\n",
    "- Repete-se o mesmo processo.\n",
    "- Multiplica-se o vetor resultante por $W^{[2]}$ e adiciona-se a sua interceptação (bias). \n",
    "- Finalmente, determina-se a sigmoid do resultado. Se for maior que 0.5, classifica-se como um gato.\n",
    "\n",
    "### 3.2 - Rede Neural Profunda com L camadas\n",
    "\n",
    "É difícil representar um rede neural profunda com L camadas da forma mostrada acima. De qualquer forma, segue uma rede simplificada:\n",
    "\n",
    "<img src=\"images/LlayerNN_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "<caption><center> <u>Figura 3</u>: Rede Neural com L camadas escondidas. <br> O modelo pode ser resumido como: ***[LINEAR -> RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID***</center></caption>\n",
    "\n",
    "<u>Detalhes da arquitetura da figura 3</u>:\n",
    "- A imagem de entrada possui formato (64,64,3) transformada em vetor do tamanho (12288,1).\n",
    "- O vetor: $[x_0,x_1,...,x_{12287}]^T$ é multiplicado pelo peso da matriz $W^{[1]}$ e se adiciona a interceptação $b^{[1]}$. O resultado é chamado de unidade linear.\n",
    "- Em seguida determina-se o valor do ReLu da unidade linear. Este processo pode ser repetido diversas vezes para cada $(W^{[l]}, b^{[l]})$ dependendo da arquitetura do modelo.\n",
    "- Finalmente, determina-se a sigmoid do resultado. Se for maior que 0.5, classifica-se como um gato.\n",
    "\n",
    "### 3.3 - Metodologia Geral\n",
    "\n",
    "Como sempre iremos seguir a metodologia de deep learning para construir o modelo:\n",
    "    1. Inicialize os parâmetros / Defina os hyperparâmetros\n",
    "    2. Repita por num_iterations:\n",
    "        a. Propagação para frente\n",
    "        b. Compute função custo\n",
    "        c. Propagação para trás\n",
    "        d. Atualização dos parâmetros (usando parâmetros, e grads da propagação para trás) \n",
    "    4. Use os parâmetros treinados para fazer a previsão de novos dados\n",
    "\n",
    "Vamos então implementar estes dois modelos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Rede Neural de 2 camadas\n",
    "\n",
    "**Exercício**:  Utilize as funções auxiliares que você implementou na tarefa anterior para construir uma rede neural com 2 camadas escondidas com a seguinte estrutura: *LINEAR -> RELU -> LINEAR -> SIGMOID*. As funções que você deve precisar e seus argumentos são: \n",
    "```python\n",
    "def inicializar_parametros(n_x, n_h, n_y):\n",
    "    ...\n",
    "    return parameters \n",
    "def para_frente_linear_ativacao(A_prev, W, b, activation):\n",
    "    ...\n",
    "    return A, cache\n",
    "def compute_custo(AL, Y):\n",
    "    ...\n",
    "    return cost\n",
    "def para_tras_linear_ativacao(dA, cache, activation):\n",
    "    ...\n",
    "    return dA_prev, dW, db\n",
    "def atualize_parametros(parameters, grads, learning_rate):\n",
    "    ...\n",
    "    return parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTES QUE DEFINEM O MODELO ####\n",
    "n_x = 12288     # num_px * num_px * 3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: two_layer_model\n",
    "\n",
    "def modelo_2_camadas(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implementa uma rede neural com 2 camadas escondidas: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Argumentos:\n",
    "    X -- dados de entrada no formato (n_x, numero de exemplos)\n",
    "    Y -- vetor de classificação correta (contendo 1 se gato, 0 se não-gato), no formato (1, numero de exemplos)\n",
    "    layers_dims -- tamanho de cada camada (n_x, n_h, n_y)\n",
    "    num_iterations -- numero de interações no loop de otimizacao\n",
    "    learning_rate -- taxa de aprendizadao da regra de atualizacao do gradiente descendente\n",
    "    print_cost -- se for True, imprime o custo a cada 100 interações \n",
    "    \n",
    "    Retorna:\n",
    "    parametros -- um dicionário contendo W1, W2, b1, e b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # para armazenar os valores do custo\n",
    "    m = X.shape[1]                           # numero de exemplos\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Inicializa o dicionário de parâmetros chamando uma das funções previamente implementadas\n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de código)\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    # Obtenha W1, b1, W2 e b2 do dicionário de parâmetros.\n",
    "    W1 = parametros[\"W1\"]\n",
    "    b1 = parametros[\"b1\"]\n",
    "    W2 = parametros[\"W2\"]\n",
    "    b2 = parametros[\"b2\"]\n",
    "    \n",
    "    # Loop (gradiente descendente)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Propagação para frente: LINEAR -> RELU -> LINEAR -> SIGMOID. Entrads: \"X, W1, b1\". Saídas: \"A1, cache1, A2, cache2\".\n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (≈ 2 linhas de código)\n",
    "        \n",
    "        \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    "        \n",
    "        # Compute custo\n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de código)\n",
    "        \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    "        \n",
    "        # Inicializar a propagacao para tras\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Propagacao para tras. Entradas: \"dA2, cache2, cache1\". Saídas: \"dA1, dW2, db2; e dA0 (nao usado), dW1, db1\".\n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (≈ 2 linhas de código)\n",
    "        \n",
    "        \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    "        \n",
    "        # Ajuste dos grads['dWl'] para dW1, grads['db1'] para db1, grads['dW2'] para dW2, grads['db2'] para db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Atualiza os parametros.\n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (aprox. 1 linha de codigo)\n",
    "        \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    "\n",
    "        # Obtem W1, b1, W2, b2 dos parametros\n",
    "        W1 = parametros[\"W1\"]\n",
    "        b1 = parametros[\"b1\"]\n",
    "        W2 = parametros[\"W2\"]\n",
    "        b2 = parametros[\"b2\"]\n",
    "        \n",
    "        # Imprime o custo a cada 100 exemplos de treinamento\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Custo após interação {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plota o custo\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('custo')\n",
    "    plt.xlabel('iteracoes (x 10)')\n",
    "    plt.title(\"Taxa de aprendizado =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo para treinar seus parâmetros. Veja se o modelo roda. O custo deve estar decrescendo. Leva em torno de 2 minutos para executar 2500 interações. Verifique que o custo após a interação 0 bate com o esperado, se não bater clique no botão (⬛) na barra de controle do notebook para interromper a execução e tene encontrar o erro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = modelo_2_camadas(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Custo após a interação  0**</td>\n",
    "        <td> 0.6930497356599888 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Custo após a interação 100**</td>\n",
    "        <td> 0.6464320953428849 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Custo após a interação 2400**</td>\n",
    "        <td> 0.048554785628770206 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda bem que foi utilizada vetorização na implementação, de outra forma o tempo de excução poderia ser até 10 vezes maior para treinar a rede. \n",
    "\n",
    "Agora é possível utilizar os parâmetros treinados para classificar imagens da base de daos. Para ver as previsões no conjunto de treinamento e no conjunto de teste execute a célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = prever(train_x, train_y, parametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Accuracy**</td>\n",
    "        <td> 1.0 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_test = prever(test_x, test_y, parametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Accuracy**</td>\n",
    "        <td> 0.72 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: Pode-se notar que rodando o modelo com menos interações (algo em torno de 1500) da uma precisao melhor no conjunto de teste. Isto é chamado de \"parada cedo\" e iremos falar sobre isto mais a frente. A parada cedo é uma forma de se evitar o sobreajuste.  \n",
    "\n",
    "Parabéns! A sua rede de duas camadas tem um desempenho melhor (72%) que a sua rede de regressão logística (70%) - (mesmo??). Vamos ver o que acontece quando utilizamos um modelo com $L$ camadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Rede Neural com L camadas\n",
    "\n",
    "**Exercício**: Utilize as funções auxiliares que foram implementadas na tarefa passada para construir uma rede neural com $L$ camadas escondidas, seguindo a estrutura:  *[LINEAR -> RELU]$\\times$(L-1) -> LINEAR -> SIGMOID*. As funções que você deve precisar são:\n",
    "```python\n",
    "def inicializa_parametros_deep(layer_dims):\n",
    "    ...\n",
    "    return parameters \n",
    "def modelo_para_frente_L(X, parameters):\n",
    "    ...\n",
    "    return AL, caches\n",
    "def compute_custo(AL, Y):\n",
    "    ...\n",
    "    return cost\n",
    "def modelo_para_tras_L(AL, Y, caches):\n",
    "    ...\n",
    "    return grads\n",
    "def atualize_parametros(parameters, grads, learning_rate):\n",
    "    ...\n",
    "    return parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTES ###\n",
    "layers_dims = [12288, 20, 7, 5, 1] #  modelo com 5 camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: modelo_L_camadas\n",
    "\n",
    "def modelo_L_camadas(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implementa uma rede neural com L camadas escondidas: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Argumentos:\n",
    "    X -- dados de entrada, um array numpy no formato (numero de exemplos, num_px * num_px * 3)\n",
    "    Y -- classificacao correta dos dados de entrada, um vetor (contem 1=gato, 0=nao-gato), no formato (1, numero de exemplos)\n",
    "    layers_dims -- lista contendo o tmanho da entrada e o tamanho de cada camada, de comprimento (numero de camadas + 1).\n",
    "    learning_rate -- a taxa de aprendizado para a regra de atualizacao do gradiente descendente\n",
    "    num_iterations -- numero de interacoes do loop de otimizacao\n",
    "    print_cost -- se True, imprime o custo a cada 100 interacoes\n",
    "    \n",
    "    Retorna:\n",
    "    parametros -- parametros aprendidos pelo modelo. Eles podem ser utilizados na previsao de novas saidas.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # usado para manter os valores de custo\n",
    "    \n",
    "    # Parametros de inicializacao.\n",
    "    ### INICIE O SEU CÓDIGO AQUI ###\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    # Loop (gradiente descendente)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Propagacao para frente: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de codigo)\n",
    "        \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    "        \n",
    "        # Compute custo.\n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de codigo)\n",
    "       \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "        # propagacao para tras.\n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de codigo)\n",
    "        \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    " \n",
    "        # Atualiza parametros.\n",
    "        ### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de codigo)\n",
    "        \n",
    "        ### TÉRMINO DO CÓDIGO ###\n",
    "                \n",
    "        # Imprime o custo a cada 100 interacoes\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('custo')\n",
    "    plt.xlabel('interacoes (* 10)')\n",
    "    plt.title(\"Taxa de aprendizado =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida iremos treinar o modelo de rede neural com 5 camadas escondidas. \n",
    "\n",
    "Execute a célula abaixo para treinar o modelo. O custo deve decrescer em cada interação. Isto deve levar algo em torno de 2 a 3 minutos para as 2500 interações. Verifique o custo após a interação 0 se o valor é igual ao esperado, caso não seja, ckique no botão (⬛) na barra superior do notebook para interromper a execução e verifique onde está o erro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters = modelo_L_camadas(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Custo após interacao 0**</td>\n",
    "        <td> 0.771749 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Custo após interacao 100**</td>\n",
    "        <td> 0.672053 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Custo após interacao 2400**</td>\n",
    "        <td> 0.092878 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_train = prever(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "    **Precisao Treinamento**\n",
    "    </td>\n",
    "    <td>\n",
    "    0.985645933014\n",
    "    </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = prever(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Precisao no Teste**</td>\n",
    "        <td> 0.8 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parabéns! Parece que a sua rede neural de 5 camadas tem um desempenho melhor (80%) do que a sua rede neural de 2 camadas (72%) na mesma base de dados. \n",
    "\n",
    "Este é considerado um bom desempenho para este tipo de tarefa. Bom trabalho! \n",
    "\n",
    "No próximo modulo veremos como melhorar o desempenho de uma rede neural profunda, você verá como obter precisões ainda maiores ajustando os hyperparametros sistematicamente (learning_rate, layers_dims, num_iterations, e outros que serão apresentados no proximo modulo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6) Analise de resultados\n",
    "\n",
    "Primeiro vamos ver algumas imagens onde a rede de L camadas classificou a imagem erradamente. Isto irá mostrar algumas imagens classificadas incorretamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_mislabeled_images(classes, test_x, test_y, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alguns tipos de imagens onde o modelo tende a errar inclui:** \n",
    "- Corpo do gato em uma posição não usual.\n",
    "- O gato aparece contra um background de cor similar.\n",
    "- Cor de gato incomum ou especie incomum.\n",
    "- Ângulo da camera.\n",
    "- Brilho da imagem\n",
    "- Variação da escala (gato é muito pequeno ou muito grande na imagem) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Teste com sua própria imagem (opcional) ##\n",
    "\n",
    "Parabéns, você concluiu esta tarefa. Agora você pode utilizar a sua própria imagem e ver a saída do modelo. Execute os seguintes passos:\n",
    "    1. Clique em \"File\" na barra superior deste notebook, e clique em \"Open\" para ir para o diretório da tarefa.\n",
    "    2. Adicione a sua imagem para o diretório do notebook, no diretório \"images\".\n",
    "    3. Modifique o nome da imagem no código abaixo.\n",
    "    4. Execute o código e veja se o algoritmo acertou a classificação (1 = gato, 0 = não-gato)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## INICIE O SEU CÓDIGO AQUI ##\n",
    "my_image = \"img219.jpg\" # troque aqui o nome do arquivo \n",
    "my_label_y = [0] # indique aqui a classe real da sua imagem (1 -> gato, 0 -> nao-gato)\n",
    "## TÉRMINO DO CÓDIGO ##\n",
    "\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\n",
    "my_predicted_image = prever(my_image, my_label_y, parameters)\n",
    "\n",
    "plt.imshow(image)\n",
    "print (\"y = \" + str(np.squeeze(my_predicted_image)) + \", seu modelo de L camadas indica que a imagem é um \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**:\n",
    "\n",
    "- Para recarregar o módulo externo: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "TSPse",
   "launcher_item_id": "24mxX"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
