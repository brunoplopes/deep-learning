{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Básico com Numpy (exercício opcional)\n",
    "\n",
    "Bem-vindo ao seu primeiro exercício. Este exercício irá proporcionar uma breve introdução a Python. Mesmo que você já tenha utilizado Python antes, este exercício irá te ajudar a se familiarizar com funções que serão utilizadas ao longo deste curso.   \n",
    "\n",
    "**Instruções:**\n",
    "- Você irá utilizar Python 3.\n",
    "- Evite usar for-loops e while-loops, a menos que seja dito para você usá-los.\n",
    "- Não modifique o (# FUNÇÃO de AVALIAÇÃO [nome da função]) comentada em algumas células. Seu trabalho não será avaliado se você modificar estes nomes. Cada célula contendo este tipo de comentário deve ter apenas uma função. \n",
    "- Após codificar a sua função, execute a célula imediatamente abaixo da função para verificar se o resultado obtido está correto.\n",
    "\n",
    "**Após este exercício você deverá ser capaz de:**\n",
    "- Utilizar os notebooks do iPython.\n",
    "- Utilizar funções do numpy e operações do numpy matrix/vector.\n",
    "- Compreender os conceitos de \"broadcasting\"\n",
    "- Ser capaz de vetorizar um código.\n",
    "\n",
    "Muito bem, vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre notebooks iPython ##\n",
    "\n",
    "Notebooks iPython são formas interativas de ambientes de codificação embutidos em uma página da web. Você irá utilizar notebooks iPython ao longo deste curso. Você precisa escrever código entre os comentários ### INICIE SEU CÓDIGO AQUI ### e ### TÉRMINO DO CÓDIGO ### . Após escrever seu código você pode executar a célula usando \"SHIFT\"+\"ENTER\" ou clicando no botão \"Run Cell\" (indicado pelo símbolo play) na barra superior do notebook. \n",
    "\n",
    "Geralmente será especificado o número esperado de linhas de código \"(≈ X linhas de código)\" nos comentários para indicar a você o que é esperado. Este número é uma estimativa e não se preocupe se seu código estiver com mais ou menos linhas.\n",
    "\n",
    "**Exercício**: coloque como valor para teste `\"Bom dia mundo Python...\"` na célula abaixo para imprimir  \"Bom dia mundo Python...\" e execute as duas células abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de código)\n",
    "teste = \"Bom dia mundo ...\"\n",
    "### TÉRMINO DO CÓDIGO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"teste: \" + teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "teste: Bom dia mundo Python..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**O que você precisa lembrar**:\n",
    "- Execute as células utilizando SHIFT+ENTER (ou \"Run cell\")\n",
    "- Escreva os códigos na área designada utilizando apenas Python 3\n",
    "- Nunca modifique o código fora da área designada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Construindo funções básicas com numpy ##\n",
    "\n",
    "Numpy é o pacote principal do Python para computação científica. Ela é mantida por uma grande comunidade (www.numpy.org). Neste exercício você irá aprender várias funções chave do numpy, como np.exp, np.log, and np.reshape. Você precisará saber como utilizá-las em exercícios futuros.\n",
    "\n",
    "### 1.1 - função sigmoid, np.exp() ###\n",
    "\n",
    "Antes de utilizar np.exp(), você utilizará o math.exp() para implemetar a função sigmoid. Assim você irá compreender o porque a função np.exp() é preferível no lugar da math.exp().\n",
    "\n",
    "**Exercício**: Construa uma função que retorne o sigmoid de um número real x. Utilize math.exp(x) para a função exponencial. \n",
    "\n",
    "**Lembre-se que**:\n",
    "    $sigmoid(x) = \\frac{1}{1+e^{-x}}$ que também é conhecida como função logística. É uma função não linear utilizada não apenas em Aprendizado de Máquinas (Regressão logística), mas também em Deep Learning.\n",
    "\n",
    "<img src=\"images/Sigmoid.png\" style=\"width:500px;height:228px;\">\n",
    "\n",
    "Para se referir a uma função que pertence a um determinado pacote você poderia fazer a chamada utilizando o nome do pacote nome_pacote.função(). Execute o código abaixo para ver um exemplo com math.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: sigmoid_basica\n",
    "\n",
    "import math\n",
    "\n",
    "def sigmoid_basica(x):\n",
    "    \"\"\"\n",
    "    Determina o sigmoid de x.\n",
    "\n",
    "    Argumentos:\n",
    "    x -- Um escalar\n",
    "\n",
    "    Retorna:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de código)\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_basica(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**: \n",
    "<table style = \"width:40%\">\n",
    "    <tr>\n",
    "    <td>** sigmoid_basica(3) **</td> \n",
    "        <td>0.9525741268224334 </td> \n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na verdade, raramente a biblioteca \"math\" é utilizada em deep learning porque as entradas das funções são números reais. Em Deep Learning as entradas são geralmente matrizes e vetores. Por isto a biblioteca numpy é mais útil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uma das razões para se utilizar a biblioteca \"numpy\" no lugar da \"math\" em Deep Learning ###\n",
    "x = [1, 2, 3]\n",
    "sigmoid_basica(x) # você verá que a execução deste comando irá dar um erro, isto ocorre porque x é um vetor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato, se $ x = (x_1, x_2, ..., x_n)$ é um vetor linha, então $np.exp(x)$ irá aplicar a função exponencial a cada elemento de x. A saída será: $np.exp(x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# exemplo de np.exp\n",
    "x = np.array([1, 2, 3])\n",
    "print(np.exp(x)) # result is (exp(1), exp(2), exp(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda, se x é um vetor, então uma operação em Python como $s = x + 3$ ou $s = \\frac{1}{x}$ irá retornar s como um vetor do mesmo tamanho de x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo de operação com vetor\n",
    "x = np.array([1, 2, 3])\n",
    "print (x + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A qualquer momento que você precisar de mais informação sobre a função numpy.exp(), de uma olhada em [documentação oficial](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html). \n",
    "\n",
    "Você pode ainda criar uma nova célula no seu notebook e escrever `np.exp?` (por exemplo) para acessar a documentação rapidamente. \n",
    "\n",
    "**Exercício**: Implemente a função sigmoid utilizando numpy. \n",
    "\n",
    "**Instruções**: x pode ser tanto um número real, um vetor ou uma matriz. A estrutura de dados utilizada em numpy para representar estas formas (vetores, matrizes, ...) são chamadas de arrays em numpy. Por enquanto você não precisa saber mais sobre isto. \n",
    "$$ \\text{Para } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix}\\tag{1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: sigmoid\n",
    "\n",
    "import numpy as np # isto quer dizer que você pode acessar uma função numpy usando np.função() no lugar de numpy.função()\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any size\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI  ### (≈ 1 linha de código)\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**: \n",
    "<table>\n",
    "    <tr> \n",
    "        <td> **sigmoid([1,2,3])**</td> \n",
    "        <td> array([ 0.73105858,  0.88079708,  0.95257413]) </td> \n",
    "    </tr>\n",
    "</table> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Gradiente da Sigmoid\n",
    "\n",
    "Como foi visto na aula, é preciso determinar gradientes para poder otimizar as funções de perda quando utilizamos a backpropagation. Vamos codificar a nossa primeira função gradiente. \n",
    "\n",
    "**Exercício**: Implemente a função derivativa_sigmoid() para computar o gradiente da função sigmoid com relação a sua entrada x. A formula é: $$derivativa\\_sigmoid(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$\n",
    "Normalmente esta função é codificada em duas etapas:\n",
    "1. Ajusta s para ser o sigmoid de x. Você pode utilizar a sua função sigmoid(x) se quiser.\n",
    "2. Compute $\\sigma'(x) = s(1-s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: derivativa_sigmoid\n",
    "\n",
    "def derivativa_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Determina o gradiente (também chamado de inclinação ou derivativa) da função sigmoid com relação a sua entrada x.\n",
    "    Você pode armazenar a saída da função sigmoid em variáveis e então utilizá-las para calcular o gradiente.\n",
    "    \n",
    "    Argumentos:\n",
    "    x -- Um escalar ou um array numpy\n",
    "\n",
    "    Retorna:\n",
    "    ds -- O gradiente calculado.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 2 linhas de código)\n",
    "    \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "print (\"derivativa_sigmoid(x) = \" + str(derivativa_sigmoid(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**: \n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr> \n",
    "        <td> **derivativa_sigmoid([1,2,3])**</td> \n",
    "        <td> [ 0.19661193  0.10499359  0.04517666] </td> \n",
    "    </tr>\n",
    "</table> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Reformatando arrays ###\n",
    "\n",
    "Duas funções comuns em numpy utilizadas em deep learning são [np.shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) e [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html). \n",
    "- X.shape é utilizado para obter a forma (dimensões) de uma matriz/vetor X. \n",
    "- X.reshape(...) é utilizado para reformatar X em alguma outra dimensão. \n",
    "\n",
    "Por exemplo, em ciência da computação, uma imagem é representada por um array em 3D no formato $(comprimento, altura, profundidade = 3)$. Porém, quando você lê uma imagem como uma entrada de um algoritmo você a converte pra um vetor no formato   $(comprimento*altura*3, 1)$. Em outras palavras, você \"desenrola\", ou reformata, o array em 3D em um vetor em 1D.\n",
    "\n",
    "<img src=\"images/image2vector_kiank.png\" style=\"width:500px;height:300;\">\n",
    "\n",
    "**Exercício**: Implemente `imagemParaVetor()` que recebe uma entrada no formato (comprimento, altura, 3) e retorna um vetor no formato (comprimento\\*altura\\*3, 1). Por exemplo, se você quiser reformatar um array v do formato (a, b, c) para o formato (a*b,c) você deve executar o comando:\n",
    "``` python\n",
    "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n",
    "```\n",
    "- Por favor não codifique as dimensões de uma imagem como uma constante. Em vez disso, olhe as dimensões que você precisa com o comando `image.shape[0]`, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: imagemParaVetor\n",
    "def imagemParaVetor(imagem):\n",
    "    \"\"\"\n",
    "    Argumento:\n",
    "    imagem -- um array numpy array no formato (comprimento, altura, profundidade)\n",
    "    \n",
    "    Retorna:\n",
    "    v -- um vetor no formato (comprimento*altura*profundidade, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI ### (≈ 1 linha de código)\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB values\n",
    "imagem = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print (\"imagemParaVetor(imagem) = \" + str(imagemParaVetor(imagem)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**: \n",
    "\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "     <tr> \n",
    "       <td> **imagemParaVetor(image)** </td> \n",
    "       <td> [[ 0.67826139]\n",
    " [ 0.29380381]\n",
    " [ 0.90714982]\n",
    " [ 0.52835647]\n",
    " [ 0.4215251 ]\n",
    " [ 0.45017551]\n",
    " [ 0.92814219]\n",
    " [ 0.96677647]\n",
    " [ 0.85304703]\n",
    " [ 0.52351845]\n",
    " [ 0.19981397]\n",
    " [ 0.27417313]\n",
    " [ 0.60659855]\n",
    " [ 0.00533165]\n",
    " [ 0.10820313]\n",
    " [ 0.49978937]\n",
    " [ 0.34144279]\n",
    " [ 0.94630077]]</td> \n",
    "     </tr>\n",
    "    \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - Normalizando linhas\n",
    "\n",
    "Uma outra técnica comum utilizada em Aprendizado de Máquinas e Deep Learning é a técnica de normalização de dados. Ela normalmente nos leva a um melhor desempenho porque o gradiente descendente converge mais rápido após a normalização. Aqui, o termo normalização significa trocar x $ \\frac{x}{\\| x\\|} $ (dividindo cada linha do vetor de x pela sua norm).\n",
    "\n",
    "Por exemplo, se $$x = \n",
    "\\begin{bmatrix}\n",
    "    0 & 3 & 4 \\\\\n",
    "    2 & 6 & 4 \\\\\n",
    "\\end{bmatrix}\\tag{3}$$ então $$\\| x\\| = np.linalg.norm(x, axis = 1, keepdims = True) = \\begin{bmatrix}\n",
    "    5 \\\\\n",
    "    \\sqrt{56} \\\\\n",
    "\\end{bmatrix}\\tag{4} $$e        $$ x\\_normalized = \\frac{x}{\\| x\\|} = \\begin{bmatrix}\n",
    "    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n",
    "    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n",
    "\\end{bmatrix}\\tag{5}$$ Note que você pode dividir matrizes de tamanhos diferentes e funciona sem problemas: isto é chamado de broadcasting e você vai aprender sobre isto na parte 5.\n",
    "\n",
    "\n",
    "**Exercício**: Implemente normalizaLinhas() para normalizar as linhas de uma matriz. Após aplicar esta função para uma matriz de entrada x, cada linha de x será um vetor de comprimento unitário (ou seja comprimento 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: normalizaLinhas\n",
    "\n",
    "def normalizaLinhas(x):\n",
    "    \"\"\"\n",
    "    Implemente a função que normaliza cada linha de uma matriz x (para ter comprimento unitário).\n",
    "    \n",
    "    Argumento:\n",
    "    x -- Uma matriz numpy matrix no formato (n, m)\n",
    "    \n",
    "    Retorna:\n",
    "    x -- A matriz numpy normalizada (por linha). Você tem permissão para modificar x.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI  ### (≈ 2 linhas de código)\n",
    "    # Compute x_norm como a norm 2 de x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "   \n",
    "    \n",
    "    # Divida x pela sua norm.\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([\n",
    "    [0, 3, 4],\n",
    "    [1, 6, 4]])\n",
    "print(\"normalizaLinhas(x) = \" + str(normalizaLinhas(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**: \n",
    "\n",
    "<table style=\"width:60%\">\n",
    "\n",
    "     <tr> \n",
    "       <td> **normalizaLinhas(x)** </td> \n",
    "       <td> [[ 0.          0.6         0.8       ]\n",
    " [ 0.13736056  0.82416338  0.54944226]]</td> \n",
    "     </tr>\n",
    "    \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**:\n",
    "Em normalizaLinhas(), você pode tentar imprimir os formatos de x_norm e x, e então executar a avaliação. Você verá que eles possuem formas diferentes. Isto é normal dado que x_norm pega a norm de cada linha de x. Logo x_norm possui o mesmo número de linhas mas apenas 1 coluna. Então, como isto funciona quando você divide x pela x_norm? Isto é chamado de broadcasting e nós vamos falar sobre isto agora!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - Broadcasting e a função softmax  ####\n",
    "Um conceito importante para se entender em numpy é o \"broadcasting\". Ele é muito útil n desempenho de operações matemáticas entre arrays de formatos diferentes. Para detalhes mais completos sobre broadcasting leia no site oficial [documentação sobre broadcasting](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício**: Implemente a função softmax utilizando numpy. Você pode pensar na função softmax como uma função de normalização utilizada quando o algoritmo precisa classificar entre duas ou mais classes. Você irá aprender mais sobre softmax ainda neste curso mas em módulos mais avançados. \n",
    "\n",
    "**Instruções**\n",
    "- $ \\text{para } x \\in \\mathbb{R}^{1\\times n} \\text{,     } softmax(x) = softmax(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix} $ \n",
    "\n",
    "- $\\text{para uma matriz } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ mapeia para o elemento na linha $i$ e coluna $j$ de $x$, portanto tem-se: }$  $$softmax(x) = softmax\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} = \\begin{pmatrix}\n",
    "    softmax\\text{(primeira linha de x)}  \\\\\n",
    "    softmax\\text{(segunda linha de x)} \\\\\n",
    "    ...  \\\\\n",
    "    softmax\\text{(última linha de x)} \\\\\n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: softmax\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Calcula o valor da função softmax para cada linha da entrada x.\n",
    "\n",
    "    Seu código deve funcionar para um vetor linha e também para matrizes no formato (n, m).\n",
    "\n",
    "    Argumento:\n",
    "    x -- Uma matriz numpy no formato (n,m)\n",
    "\n",
    "    Retorna:\n",
    "    s -- Uma matriz numpy igual ao softmax de x, no formato (n,m)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI  ### (≈ 3 linhas de código)\n",
    "    # Aplique exp() em cada elemento de x. Use np.exp(...).\n",
    "    \n",
    "\n",
    "    # Crie um vetor x_soma que some cada linha de x_exp. Use np.sum(..., axis = 1, keepdims = True).\n",
    "   \n",
    "    \n",
    "    # Compute softmax(x) dividindo x_exp por x_soma. Ele deve automaticamente utilizar o broadcasting do numpy.\n",
    "   \n",
    "\n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "\n",
    "     <tr> \n",
    "       <td> **softmax(x)** </td> \n",
    "       <td> [[  9.80897665e-01   8.94462891e-04   1.79657674e-02   1.21052389e-04\n",
    "    1.21052389e-04]\n",
    " [  8.78679856e-01   1.18916387e-01   8.01252314e-04   8.01252314e-04\n",
    "    8.01252314e-04]]</td> \n",
    "     </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**:\n",
    "- Se você imprimir o formato de x_exp, x_soma e s acima e executar a célula novamente, você verá que x_soma está no formato (2,1) enquanto que x_exp e s estão no formato (2,5). **x_exp/x_soma** só funciona devido ao broadcasting do Python. \n",
    "\n",
    "Parabéns! Agora você já consegue entender como a biblioteca numpy do Python implementa uma série de funções uteis em algoritmos de deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**O que você precisa lembrar:**\n",
    "- np.exp(x) funciona para qualquer array np x e aplica a função exponencial para todos os elementos de x.\n",
    "- a função sigmoid e seu gradiente.\n",
    "- imagemParaVetor é bastante utilizada em deep learning.\n",
    "- np.reshape é bastante utilizada. No futuro, você verá que manter a dimensão de sua matriz/vetor de forma correta irá ajudar a eliminar uma série de problemas de debug no código. \n",
    "- numpy possui uma série de funções eficientes em sua biblioteca.\n",
    "- broadcasting é bastante útil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2) Vectorização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Em deep learning, você irá lidar com conjuntos de dados muito grandes. Logo, uma função computacional que não seja ótima pode se tornar um grande gargalo no seu algoritmo e pode tornar seu modelo um sistema muito lento. Para ter certeza que seu código é computacionalmente eficiente você deverá utilizar vetorização. Por exemplo, tente mostrar a diferença entre as seguintes implementações dos produtos dot/outer/elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO DOT ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot+= x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Tempo de Processamento = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO OUTER ###\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1),len(x2))) # criamos uma matriz de zeros de tamanho len(x1)*len(x2) \n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i]*x2[j]\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Tempo de Processamento = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO ELEMENTO A ELEMENTO ###\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"multiplicação elemento a elemento = \" + str(mul) + \"\\n ----- Tempo de Processamento = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### IMPLEMENTAÇÃO GERAL DO PRODUTO DOT ###\n",
    "W = np.random.rand(3,len(x1)) # array numpy com Random 3*len(x1)\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(gdot) + \"\\n ----- Tempo de Processamento = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### FORMA VETORIZADA DO PRODUTO DOT DE VETORES ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Tempo de Processamento = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### FORMA VETORIZADA DO PRODUTO OUTER ###\n",
    "tic = time.process_time()\n",
    "outer = np.outer(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Tempo de Processamento = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### FORMA VETORIZADA DE MULTIPLICAÇÃO DE ELEMENTO A ELEMENTO ###\n",
    "tic = time.process_time()\n",
    "mul = np.multiply(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"multiplicação elemento a elemento = \" + str(mul) + \"\\n ----- Tempo de Processamento = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### FORMA VETORIZADA GERAL DO PRODUTO DOT ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(W,x1)\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(dot) + \"\\n ----- Tempo de Processamento = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como você deve ter notado, a implementação vetorizada é mais limpa e também mais eficiente (embora para o exemplo acima os tempos tenham sido semelhantes) Para vetores ou matrizes maiores a diferença em tempo de processamento é bem maior.  \n",
    "\n",
    "**Nota:** veja que `np.dot()` executa uma multiplicação matriz-matriz ou matriz-vetor. Esta é a diferença de `np.multiply()` e o operador `*` (que é equivalente a  `.*` em Matlab/Octave), e que executa uma multiplicação elemento a elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Implementando as funções de perda L1 e L2 \n",
    "\n",
    "**Exercício**: Implemente uma versão vetorizada, utilizando numpy, da função de perda L1. A função abs(x) (valor absoluto de x) pode ser útil.\n",
    "\n",
    "**Lembre-se**:\n",
    "- A função de perda é utilizada para avaliar o desempenho de um modelo. Quanto maior o valor da perda maior a diferença entre a previsão ($ \\hat{y} $) com relação ao valor real ($y$). Em deep learning, utilizam-se algoritmos de otimização como o Gradiente Descendente para treinar o modelo e minimizar o custo. \n",
    "- A perda L1 é definida como:\n",
    "$$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=0}^m|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}\\tag{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: L1\n",
    "\n",
    "def L1(yhat, y):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    yhat -- vetor de tamanho m (valores estimados)\n",
    "    y -- vetor de tamanho m (valores reais)\n",
    "    \n",
    "    Retorna:\n",
    "    perda -- o valor da função de perda L1 definido acima\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI  ### (≈ 1 linha de código)\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO  ###\n",
    "    \n",
    "    return perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**:\n",
    "\n",
    "<table style=\"width:20%\">\n",
    "\n",
    "     <tr> \n",
    "       <td> **L1** </td> \n",
    "       <td> 1.1 </td> \n",
    "     </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício**: Implemente uma versão vetorizada, utilizando numpy, da função de perda L2. Existem diversas formas de se implementar a função de perda L2, neste caso a função np.dot() pode ser útil. Lembre-se que, se $x = [x_1, x_2, ..., x_n]$, então `np.dot(x,x)` = $\\sum_{j=0}^n x_j^{2}$. \n",
    "\n",
    "- A função de perda L2 é definida como $$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^m(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}\\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: L2\n",
    "\n",
    "def L2(yhat, y):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    yhat -- vetor de tamanho m (valores estimados)\n",
    "    y -- vetor de tamanho m (valores reais)\n",
    "    \n",
    "    Retorna:\n",
    "    perda -- o valor da função de perda L2 definido acima\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI  ### (≈ 1 linha de código)\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    return perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L2 = \" + str(L2(yhat,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída Esperada**: \n",
    "<table style=\"width:20%\">\n",
    "     <tr> \n",
    "       <td> **L2** </td> \n",
    "       <td> 0.43 </td> \n",
    "     </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parabéns, você completou este trabalho. Esperamos que este aquecimento venha a ajudá-lo em trabalhos futuros, que devem ser mais interessantes e mais desafiadores! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**Lembre-se:**\n",
    "- Vetorização é muito importante no desempenho de algoritmos de deep learning. Ela melhora a eficiência e deixa o código mais limpo.\n",
    "- Foram revisadas as funções de perda L1 e L2.\n",
    "- Você se familiarizou com muitas funções numpy, como np.sum, np.dot, np.multiply, np.maximum, etc..."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XHpfv",
   "launcher_item_id": "Zh0CU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
