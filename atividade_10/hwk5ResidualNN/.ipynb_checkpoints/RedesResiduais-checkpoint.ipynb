{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Residuais\n",
    "\n",
    "Vamos dar continuidade ao aprendizado com Keras na segunda tarefa desta semana! Voce irá aprender como construir uma rede convolucional profunda utilizando redes residuais (ResNets). Na teoria, redes muito profundas podem representar funções bastante complexas; porém, na prática, elas são dificeis de serem treinadas. Redes Residuais, introduzidas por [He et al.](https://arxiv.org/pdf/1512.03385.pdf), permitem  treinar redes muito profundas que anteriormente não era possível de ser realizado.\n",
    "\n",
    "**Nesta tarefa você irá:**\n",
    "- Implementar os blocos básicos de uma ResNet. \n",
    "- Ligar estes blocos para implementar e treinar uma rede neural de última geração para classificar imagens.  \n",
    "\n",
    "Esta tarefa será feita utilizando Keras. \n",
    "\n",
    "Vamos exeutar a célula abaixo para carregar todos os pacotes necessários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - O problema de redes neurais muito profundas\n",
    "\n",
    "Você já construiu a sua primeira rede neural convolucional. Recentemente as redes neurais ficaram mais profundas, onde o estado da arte partiu de apenas algumas camadas (como na AlexNet) para mais de 100 camadas. \n",
    "\n",
    "O principal beneficio de uma rede neural muito profunda é que ela consegue representar funções muito complexas. Ela pode ainda aprender características em níveis diferentes de abstração, de arestas (nos primeiros níveis) até características complexas (nos níveis mais profundos). Porém, utilizar uma rede neural muito profunda nem sempre ajuda. Uma grande barreira para treiná-las são os gradientes que podem ir para zero muito rapidamente conforme nos aprofundamos na rede, fazendo com que o gradiente descendente seja muito lento. Mais especificamente, durante o gradiente descendente, conforme é feita  a propagação para trás da camada de saída para as camadas anteriores as matrizes de peso são multiplicadas em cada etapa e o gradiente pode ir para zero rapidamente (ou, em casos raros, crecerem exponencialmente e explodir com valores muito altos).  \n",
    "\n",
    "Durante o treinamento você deve verificar se a magnitude (ou a norm) do gradiente para as camadas anteriores estão decrescendo para zero conforme o processo de treinamento caminha:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/vanishing_grad_kiank.png\" style=\"width:450px;height:220px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 1** </u><font color='purple'>  : **Gradiente indo a zero** <br> A velocidade do treinamento decresce rapidamente nas camadas iniciais durante o treinamento da rede</center></caption>\n",
    "\n",
    "Uma rede residual irá nos auxiliar a resolver este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Construindo uma rede residual\n",
    "\n",
    "Em ResNets, um  \"atalho\" ou uma \"conexão escapada\" permite que o gradiente seja diretamente propagado para camadas menos profundas:  \n",
    "\n",
    "<img src=\"images/skip_connection_kiank.png\" style=\"width:650px;height:200px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figura 2** </u><font color='purple'>  : Um bloco de ResNet mostrando uma **conexão escapada** <br> </center></caption>\n",
    "\n",
    "A imagem à esquerda mostra o caminho principal através da rede. A imagem à direita mostra umbloco ResNet que adiciona um atalho ao caminho principal. Ligando blocos ResNet é possível construir uma rede muito profunda.  \n",
    "\n",
    "Foi visto também em aula que os blocos ResNet tornam o aprendizado da função identidade algo bem simples. Isto quer dizer que  você pode adicionar blocos ResNet sem o risco de prejudicar o desempenho da rede durante o treinamento. (Existem evidências de que a facilidade de aprender a função identidade, mais do que auxiliar nos gradientes indo para zero, é um dos fatores do ótimo desempenho das ResNets.) \n",
    "\n",
    "Uma ResNet utiliza dois tipos de blocos, dependendo principalmente no fato das dimensões de entrada e saída serem ou não as mesmas. Você irá implementar os dois casos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - O bloco identidade\n",
    "\n",
    "O bloco identidade é um blocopadrão utilizado em ResNets e corresponde ao caso onde a ativação de entrada ($a^{[l]}$) possui a mesma dimensão da saída da ativação ($a^{[l+2]}$). Para ilustrar os passos do que acontece em um bloco de identidade de uma ResNet a figura abaixo mostra um diagrama alternativo:\n",
    "\n",
    "<img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figura 3** </u><font color='purple'>  : **Bloco Identidade.** Conexão escapada \"escapa sobre\" 2 camadas. </center></caption>\n",
    "\n",
    "O caminho de cima é o \"atalho\". O caminho de baixo éo caminho principal. Neste diagrama está sendo apresentado explicitamente os passos da CONV2D e ReLU em cada camada. Para acelerar o treinamento foi adicionado um passo de BatchNorm. Não se preocupe se você achar isto tudo muito complicado, você verá que, por exemplo, BatchNorm é apenas uma linha de código em Keras! \n",
    "\n",
    "Neste exercício você irá implementar uma versão ainda mais poderosa do bloco de identidade, onde a conexão escapada pula 3 camadas ao invés de 2. Ele se parece com isto: \n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figura 4** </u><font color='purple'>  : **Bloco Identidade.** Conexão escapada sobre 3 camadas.</center></caption>\n",
    "\n",
    "Estes são os passos individuais.\n",
    "\n",
    "Primeira componente do caminho principal: \n",
    "- O primeiro CONV2D possui $F_1$ filtros no formato (1,1) e com stride de (1,1). O padding utilizado é \"valid\" e seu nome deve ser `conv_name_base + '2a'`. Use 0 como semente para as inicializações aleatórias. \n",
    "- O primeiro BatchNorm estará normalizando o eixo dos canais.  Seu nome deve ser `bn_name_base + '2a'`.\n",
    "- Aplique então a função de ativação ReLU. Ela não possui nome e nem hiper parâmetros. \n",
    "\n",
    "Segunda componente do caminho principal: \n",
    "- O segundo CONV2D possui $F_2$ filtros no formato $(f,f)$ e com stride de (1,1). O padding utilizado é \"same\" e seu nome deve ser `conv_name_base + '2b'`. Use 0 como semente para as inicializações aleatórias. \n",
    "- O segundo BatchNorm estará normalizando o eixo dos canais. Seu nome deve ser `bn_name_base + '2b'`.\n",
    "- Aplique então a função de ativação ReLU. Ela não possui nome e nem hiper parâmetros.  \n",
    "\n",
    "Terceira componente do caminho principal: \n",
    "- O terceiro CONV2D possui $F_3$ filtros no formato (1,1) e com stride de (1,1). O padding utilizado é \"valid\" e seu nome deve ser `conv_name_base + '2c'`. Use 0 como semente para as inicializações aleatórias.\n",
    "- O terceiro BatchNorm estará normalizando o eixo dos canais.  Seu nome deve ser `bn_name_base + '2c'`. Note que não existe função de ativação neste componente. \n",
    "\n",
    "Componente Final: \n",
    "- O atalho e a entrada são adicionados.\n",
    "- A função de ativação ReLU é aplicada a esta soma. Ela não possui nome e nem hiper parâmetros. \n",
    "\n",
    "**Exercício**: Implemente o bloco de identidade da ResNet. A primeira componente do caminho principal foi implementada. Por favor leia atentamente estas instruções para entender o que você está fazendo. Você deve implementar as demais componentes.  \n",
    "- Para implementar a Conv2D: [Veja a referência](https://keras.io/layers/convolutional/#conv2d)\n",
    "- Para implementar a BatchNorm: [Veja a referência](https://faroit.github.io/keras-docs/1.2.2/layers/normalization/) (axis: Integer, o eixo que deve ser normalizado (typicamente o eixo dos canais))\n",
    "- Para a ativação utilize:  `Activation('relu')(X)`\n",
    "- Para adicionar os valores passados para frente pelo atalho: [Veja referência](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE ATIVAÇÃO: identity_block\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementa o bloco de identidade definido na figura 3\n",
    "    \n",
    "    Argumentos:\n",
    "    X -- tensor de entrada no formato (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- inteiro, especifica o formato do meio da janela do CONV para o caminho principal.\n",
    "    filters -- lista python de inteiros, definindo o número de filtros nas camadas CONV do caminho principal\n",
    "    stage -- inteiro, utilizado para dar nome as camadas, dependendo de sua posição na rede.\n",
    "    block -- string/caracter, usado para dar nome as camadas, dependendo de sua posição na rede.\n",
    "    \n",
    "    Retorna:\n",
    "    X -- saída do bloco identidade, um tensor no formato (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # definindo os nomes base\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Recupera os Filtros\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Salva o valor da entrada. Ela será necessária mais tarde para adição no caminho principal. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # Primeiro componente do caminho principal\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### INICIE SEU CÓDIGO AQUI ###\n",
    "    \n",
    "    # Segundo componente do caminho principal (≈3 linhas)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides =(1,1),padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Terceiro componente do caminho principal (≈2 linhas)\n",
    "    X = Conv2D(filters = F3, kernel_size =(1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Componente final: Adiciona o valor do atalho ao caminho principal, aplica a função de ativação RELU (2 linhas)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO AQUI ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saída = [ 0.94823   -0.         1.1610144  2.747859  -0.         1.36677  ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"saída = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **saída**\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.94822985  0.          1.16101444  2.747859    0.          1.36677003]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - O bloco de convolução\n",
    "\n",
    "Foi implementado o bloco identidade da ResNet. Em seguida, o bloco convolucional da ResNet é o próximo que iremos implementar. Você pode utilizar este tipo de bloco quando as dimensões da entrada e da saída são diferentes. A diferença, com relação ao bloco de identidade é que existe uma camada CONV2D no atalho: \n",
    "\n",
    "<img src=\"images/convblock_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figura 4** </u><font color='purple'>  : **Bloco Convolucional** </center></caption>\n",
    "\n",
    "A camada CONV2D no atalho é utilizada para redimensionar a entrada $x$ para uma dimensão diferente e compatibilizar com  a adição no final do atalho com o caminho principal. (Este bloco tem função semelhante à matriz $W_s$ discutida em aula) Por exemplo, para reduzir a dimensão da altura e largura na ativação por um fator de 2, pode-se utilizar uma convolução de 1x1 com stride igual a 2. A camada CONV2D no atalho não utiliza função de ativação não-linear. Sua função básica é aplicar uma função linear aprendida que reduz a dimensão da entrada e compatibiliza com a dimensão a ser somada no caminho principal.  \n",
    "\n",
    "Os detalhes do bloco de convolução são os seguintes: \n",
    "\n",
    "Primeiro componente do caminho principal:\n",
    "- O primeiro CONV2D possui $F_1$ filtros no formato (1,1) e com stride de (s,s). O padding utilizado é \"valid\" e seu nome deve ser `conv_name_base + '2a'`. \n",
    "- O primeiro BatchNorm normaliza o eixo dos canais.  Seu nome deve ser `bn_name_base + '2a'`.\n",
    "- Aplique a função de ativação ReLU. Está função não possui nome e nem hiper parâmetros. \n",
    "\n",
    "Segunda componente do caminho principal:\n",
    "- O segundo CONV2D possui $F_2$ filtros no formato (f,f) e uma stride de (1,1). O padding utilizado é \"same\" e seu nome deve ser `conv_name_base + '2b'`.\n",
    "- O segundo BatchNorm normaliza o eixo dos canais.  Seu nome deve ser `bn_name_base + '2b'`.\n",
    "- Aplique a função de ativação ReLu. Está função não possui nome e nem hiper parâmetros. \n",
    "\n",
    "Terceira componente do caminho principal:\n",
    "- O terceiro CONV2D possui $F_3$ filtros no formato (1,1) e uma stride de (1,1). O padding utilizado é \"valid\" e seu nome deve ser `conv_name_base + '2c'`.\n",
    "- O terceiro BatchNorm normaliza o eixo dos canais.  Seu nome deve ser `bn_name_base + '2c'`. Note que não existe uma função de ativaçào ReLU nesta componente. \n",
    "\n",
    "Atalho:\n",
    "- O CONV2D tem $F_3$ filtros no formato (1,1) e uma stride de (s,s). O padding utilizado é \"valid\" e seu nome deve ser `conv_name_base + '1'`.\n",
    "- O BatchNorm normaliza o eixo dos canais.  Seu nome deve ser `bn_name_base + '1'`. \n",
    "\n",
    "Componente Final: \n",
    "- Os valores do atalho e do caminho principal são adicionados.\n",
    "- A função de ativação ReLU é aplicada ao resultado da soma. Esta etapa não possui nome e nem hiper parâmetros. \n",
    "    \n",
    "**Exercício**: Implemente o bloco convolucional. A primeira componente do caminho principal já foi implementada para você, implemnte as demais componentes deste bloco. Como feito antes, utilize 0 como a semente para os incializadores aleatórios, para garantir consistência nos resultados. \n",
    "- [Dica Conv](https://keras.io/layers/convolutional/#conv2d)\n",
    "- [Dica BatchNorm](https://keras.io/layers/normalization/#batchnormalization) (axis: Integer, o eixo que deve ser normalizado (tipicamente o eixo de características))\n",
    "- Para a ativação utilize:  `Activation('relu')(X)`\n",
    "- [Dica Adição](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: convolutional_block\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementação do bloco convolucional como definido na Figura 4\n",
    "    \n",
    "    Argumentos:\n",
    "    X -- tensor de entrada no formato (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- inteiro, especificando o formato do meio da janela do CONV para o caminho principal.\n",
    "    filters -- uma lista do python de inteiros, definindo o número de filtros na camada CONV do caminho principal.\n",
    "    stage -- inteiro, usado para dar nomes as camadas, dependendo de sua posição na rede.\n",
    "    block -- string/caracter, usado para dar nome às camadas, dependendo de sua posição na rede.\n",
    "    s -- Inteiro, especifica o valor do stride a ser utilizado.\n",
    "    \n",
    "    Retorna:\n",
    "    X -- saída do bloco convolucional, tensor no formato (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # define o nome base\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Recupera os filtros\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Salva o valor da entrada\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### CAMINHO PRINCIPAL #####\n",
    "    # Primeira componente do caminho principal \n",
    "    X = Conv2D(F1, (1, 1), strides =(s,s), padding = 'valid', name = conv_name_base + '2a',kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### INICIE O SEU CÓDIGO AQUI ###\n",
    "\n",
    "    # Segunda componente do caminho principal (≈3 linhas)\n",
    "    X = Conv2D(F2, (f, f), strides = (1,1), padding ='same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Terceira componente do caminho principal (≈2 linhas)\n",
    "    X = Conv2D(F3, (1, 1), strides = (1,1),  padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "    \n",
    "    ##### ATALHO #### (≈2 linhas)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s),  padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Componente final: Adiciona os valores do atalho ao caminhoprincipal e passa pela função de ativação ReLU (≈2 linhas)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saída = [ 0.09018461  1.2348979   0.46822017  0.03671762 -0.          0.65516603]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"saída = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **saída**\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 0.09018463  1.23489773  0.46822017  0.0367176   0.          0.65516603]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Construindo seu primeiro modelo ResNet (50 camadas)\n",
    "\n",
    "Você já tem os blocos necessários para construir a sua primeira rede muito profunda do tipo ResNet. A Figura a seguir descreve em detalhes a arquitetura desta rede neural. \"ID BLOCK\" no diagrama significa um \"Bloco Identidade,\" e \"ID BLOCK x3\" significa que você deve combinar 3 blocos identidade juntos.\n",
    "\n",
    "<img src=\"images/resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figura 5** </u><font color='purple'>  : **ResNet-50 model** </center></caption>\n",
    "\n",
    "Os detalhes do modelo ResNet-50 são:\n",
    "- Zero-padding adiciona zeros à entrada no formato (3,3)\n",
    "- Estágio 1:\n",
    "    - A Convolução 2D possui 64 filtros no formato (7,7) e utiliza um stride de (2,2). Seu nome é \"conv1\".\n",
    "    - BatchNorm é aplicado ao eixo dos canais da entrada.\n",
    "    - MaxPooling utiliza uma janela (3,3) e um stride de (2,2).\n",
    "- Estágio 2:\n",
    "    - O bloco convolucional utiliza três conjuntos de filtros de tamanho [64,64,256], \"f\" é 3, \"s\" é 1 e o bloco é \"a\".\n",
    "    - O 2 bloco de identidade utiliza três conjuntos de filtros de tamanho [64,64,256], \"f\" é 3 e os blocos são \"b\" e \"c\".\n",
    "- Estágio 3:\n",
    "    - O bloco convolucional utiliza três conjuntos de filtros de tamanho [128,128,512], \"f\" é 3, \"s\" é 2 e o bloco é o \"a\".\n",
    "    - Os 3 blocos de identidade utilizam três conjuntos de filtros de tamanho [128,128,512], \"f\" é 3 e os blocos são \"b\", \"c\" e \"d\".\n",
    "- Estágio 4:\n",
    "    - O bloco convolucional utiliza três conjuntos de filtros de tamanho [256, 256, 1024], \"f\" é 3, \"s\" é 2 e o bloco é o \"a\".\n",
    "    - Os 5 blocos de identidade utilizam três conjuntos de filtros de tamanho [256, 256, 1024], \"f\" é 3 e os blocos são \"b\", \"c\", \"d\", \"e\" e \"f\".\n",
    "- Estágio 5:\n",
    "    - O bloco convolucional utiliza três conjuntos de filtros de tamanho [512, 512, 2048], \"f\" é 3, \"s\" é 2 e o bloco é o \"a\".\n",
    "    - Os 2 blocos de identidade utilizam três conjuntos de filtros de tamanho [512, 512, 2048], \"f\" é 3 e os blocos são \"b\" e \"c\".\n",
    "- O Average Pooling 2D utiliza uma janela no formato (2,2) e seu nome é \"avg_pool\".\n",
    "- A vetorização não possui nome ou hiper parâmetros.\n",
    "- A camada totalmente conectada (Densa) reduz sua entrada para o número de classes utilizando uma ativação do tipo softmax. Seu nome deve ser `'fc' + str(classes)`.\n",
    "\n",
    "**Exercício**: Implemente a ResNet com 50 camadas descrita na figura acima. Os estágios 1 e 2 já estão implementados, implemente o restante. (A sintaxe para implementar os estágios de 3 a 5 deve ser similares aos do 2o estágio.) Tenha certeza de seguir as convenções de nomes dados no texto acima. \n",
    "\n",
    "Voce irá precisar desta função: \n",
    "- Average pooling [veja referência](https://keras.io/layers/pooling/#averagepooling2d)\n",
    "\n",
    "Aqui estão algumas outras funções que serão usadas no código abaixo:\n",
    "- Conv2D: [Veja referência](https://keras.io/layers/convolutional/#conv2d)\n",
    "- BatchNorm: [Veja referência](https://keras.io/layers/normalization/#batchnormalization) (axis: Inteiro, o eixo onde deve ocorrer a normalização (tipicamente o eixo de características))\n",
    "- Zero padding: [Veja referência](https://keras.io/layers/convolutional/#zeropadding2d)\n",
    "- Max pooling: [Veja referência](https://keras.io/layers/pooling/#maxpooling2d)\n",
    "- Camada Fully conected: [Veja referência](https://keras.io/layers/core/#dense)\n",
    "- Addition: [Veja referência](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO DE AVALIAÇÃO: ResNet50\n",
    "\n",
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Implementação da popular ResNet50 com a seginte arquitetura:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Argumentos:\n",
    "    input_shape -- formato das imagens da base de dados.\n",
    "    classes -- inteiro, número de classes.\n",
    "\n",
    "    Retorna:\n",
    "    model -- uma instância de modelo do Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a entrada como um tensor com formato input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Estágio 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Estágio 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### INICIO DO CÓDIGO AQUI ###\n",
    "\n",
    "    # Estágio 3 (≈4 linhas)\n",
    "    X = convolutional_block(X, f = 3, filters = [128,128,512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='d')\n",
    "\n",
    "    # Estágio 4 (≈6 linhas)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f') \n",
    "\n",
    "    # Estágio 5 (≈3 linhas)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 linha). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name =\"avg_pool\")(X) \n",
    "    \n",
    "    ### TÉRMINO DO CÓDIGO ###\n",
    "\n",
    "    # Camada de saída\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Cria modelo\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo para construir o grafo do modelo. Se sua implementação não estiver correta você perceberá verificando a precisão quando executar o `model.fit(...)` abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como visto no tutorial do Keras, antes de treinar o modelo é preciso configurar oprocesso de aprendizado compilando o modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo está pronto para ser treinado. A única coisa que você precisa é uma base de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos carregar novamente a base de dados SIGNS.\n",
    "\n",
    "<img src=\"images/signs_data_kiank.png\" style=\"width:450px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figura 6** </u><font color='purple'>  : **Base de dados SIGNS** </center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normaliza os vetores das imagens\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Converte os rótulos de treinamento e teste em uma matriz do tipo one hot.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"número de exemplos de treinamento = \" + str(X_train.shape[0]))\n",
    "print (\"número de exemplos de teste = \" + str(X_test.shape[0]))\n",
    "print (\"Formato do X_train: \" + str(X_train.shape))\n",
    "print (\"Formato do Y_train: \" + str(Y_train.shape))\n",
    "print (\"Formato do X_test: \" + str(X_test.shape))\n",
    "print (\"Formato do Y_test: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo por 5 épocas com um tamanho de batch de 32. Em CPU isto deve levar em torno de 5 minutos por época.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** Época 1/5**\n",
    "        </td>\n",
    "        <td>\n",
    "           perda: entre 1 e 5, precisão: entre 0.2 e 0.5, embora seus resultados possam ser um pouco diferentes.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            ** Época 2/5**\n",
    "        </td>\n",
    "        <td>\n",
    "           perda: entre 1 e 5, precisão: entre 0.2 e 0.5, você deve ver a perda decrescer e a precisão aumentar.\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver como o seu modelo se comporta (mesmo treinado com apenas 5 épocas) no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Perda = \" + str(preds[0]))\n",
    "print (\"Precisão no teste = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Precisão do teste**\n",
    "        </td>\n",
    "        <td>\n",
    "           entre 0.16 e 0.25\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o propósito desta tarefa foi pedido para treinar o modelo em apenas 5 épocas. Você pode perceber que o desempenho não é muito bom. Após salvar o seu trabalho, caso deseje, rode o treinamento por mais épocas e compare os resultados. O desempenho melhora bem após 20 épocas, mas isto deve levar mais de 1 hora em CPU. \n",
    "\n",
    "Foi treinada uma rede igual a que você desenvolveu utilizando GPU sobre a base de dados SIGNS. Você pode carregar esta rede executando a célula abaixo e testando esta rede no conjunto de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ResNet50.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Perda = \" + str(preds[0]))\n",
    "print (\"Precisão no Teste = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 é um modelo poderoso para classificação de imagens quando treinado por um número adequado de épocas. Espero que você possa utilizar o que você aprendeu e aplicar em algum caso de classificação e obter uma precisão da ordem do estado da arte.\n",
    "\n",
    "Parabéns, você concluiu esta tarefa! Você implementou um sistema de classificação de alto nível com desempenho da ordem do estado da arte. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Teste na sua própria imagem (Opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você desejar, você pode tirar uma foto de sua mão e ver o resultado do modelo com esta foto. Para fazer isto:\n",
    "    1. Clique em \"File\" na barra superior deste notebook, e clique em \"Open\" para ir para o diretório do notebook.\n",
    "    2. Adicione sua imagem ao diretório imagens do notebook.\n",
    "    3. Escreva o nome da sua imagem na célula abaixo.\n",
    "    4. Execute o código da célula abaixo e veja se o algoritmo acerta! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'images/my_image.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)\n",
    "print('Formato da imagem de entrada:', x.shape)\n",
    "my_image = scipy.misc.imread(img_path)\n",
    "imshow(my_image)\n",
    "print(\"vetor para prever a classe [p(0), p(1), p(2), p(3), p(4), p(5)] = \")\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voce pode ainda imprimir o resumo do seu modelo executando a célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**O que você deve se lembrar:**\n",
    "- Redes normais muito profundas não funcionam na prática porque elas são dificeis de serem treinadas pois os gradientes costumam ir para zero.  \n",
    "- Os atalhos ajudam a reduzir o problema dos gradientes indo para zero. Eles também auxiliam a ResNet a aprender o bloco identidade.  \n",
    "- Existem dois tipos principais de blocos: o bloco identidade e o bloco convolucional. \n",
    "- Redes residuais muito profundas são construidas agrupando estes blocos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências \n",
    "\n",
    "Este notebook apresentou o algoritmo da ResNet desenvolvido por He et al. (2015). A implementação feita aqui teve inspiração também na estrutura dada no repositório do github de Francois Chollet: \n",
    "\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - [Deep Residual Learning for Image Recognition (2015)](https://arxiv.org/abs/1512.03385)\n",
    "- Francois Chollet's repositório github: https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OEpi5",
   "launcher_item_id": "jK9EQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
